{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bab71d-09f3-4c57-a9ad-a2380e4af784",
   "metadata": {},
   "source": [
    "# 1 - Extração de recursos de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d7f464-2b46-4248-84d1-421272e8c0f1",
   "metadata": {},
   "source": [
    "## 1.1 A Representação do modelo Bag Of Words(BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675e4e1-1670-43ba-88cc-24449174468c",
   "metadata": {},
   "source": [
    "## A Análise de Texto é um importante campo de aplicação para algoritmos de aprendizado de máquina. No entanto, os dados brutos, uma sequência de símbolos não podem ser alimentados diretamente para os próprios algoritmos, pois a maioria deles espera vetores de recursos numéricos com tamanho fixo, em vez de documentos de texto bruto com comprimento variável."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0687e-c0f6-485a-a1a6-48d86514d4e5",
   "metadata": {},
   "source": [
    "### .Para resolver isso, o scikit-learn fornece utilitários para as formas mais comuns de extrair recursos numéricos do conteúdo de texto, a saber:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee063e40-8a02-4001-a225-960990845023",
   "metadata": {},
   "source": [
    "### .Tokenizing strings e fornecendo um id inteiro para cada token possível, por exemplo, usando espaços em branco e pontuação como separadores de token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc299776-cc24-4ac8-888c-fcdd8ef50397",
   "metadata": {},
   "source": [
    "### .Normalizando e Ponderando com tokens de importância decrescente que ocorrem na maioria das amostras/documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd00f9-aebc-4628-8c7a-97205c891048",
   "metadata": {},
   "source": [
    "## Nesse esquema, os recursos e as amostras são definidos da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6caab-9ff4-41f5-aeca-ae50e828ddb3",
   "metadata": {},
   "source": [
    "### .Cada frequência de ocorrência de token individual (normalizada ou não) é tratada como um recurso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e972dcc-cc4b-49a7-bcad-335c4bb26754",
   "metadata": {},
   "source": [
    "### .O vetor de todas as frequências de token para um determinado documento é considerado uma amostra multivariada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65107d-f985-415c-acf9-1447c995b229",
   "metadata": {},
   "source": [
    "## Um corpus de documentos pode assim ser representado por uma matriz com uma linha por documento e uma coluna por token (por exemplo, palavra) ocorrendo no corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d80aff-6884-45e7-83d8-3278a60c943b",
   "metadata": {},
   "source": [
    "## Chamamos de vetorização o processo geral de transformar uma coleção de documentos de texto em vetores de recursos numéricos. Essa estratégia específica (tokenização, contagem e normalização) é chamada de representação Bag of Words ou “Bag of n-grams”. Os documentos são descritos por ocorrências de palavras, ignorando completamente as informações de posição relativa das palavras no documento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a935d54-6493-4de5-a280-87101396bbe1",
   "metadata": {},
   "source": [
    "## 1.1.2 Espasidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b8d31-9a1c-4663-87b3-1a90ba43b699",
   "metadata": {},
   "source": [
    "### Por exemplo, uma coleção de 10.000 documentos de texto curto (como e-mails) usará um vocabulário com um tamanho da ordem de 100.000 palavras únicas no total, enquanto cada documento usará de 100 a 1.000 palavras únicas individualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25908d3f-089f-4cee-8bd9-056ce471d9d6",
   "metadata": {},
   "source": [
    "### Para poder armazenar tal matriz na memória, mas também para acelerar as operações algébricas de matriz/vetor, as implementações normalmente usarão uma representação esparsa, como as implementações disponíveis no pacote scipy.sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567f8d8-492c-4ad7-a467-fb08c7ea00a2",
   "metadata": {},
   "source": [
    "## 1.1.3 Uso Comum do Vetorizador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4519d266-e011-4f08-9f93-11c97080ea86",
   "metadata": {},
   "source": [
    "### CountVectorizer implementa tokenização e contagem de ocorrências em uma única classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d2c5fa-0e01-4a05-8d6f-66da5a4430c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd12b2-c232-4729-b22a-0f2ff4cb9eaa",
   "metadata": {},
   "source": [
    "### Vamos usá-lo para tokenizar e contar as ocorrências de palavras de um corpus minimalista de documentos de texto, para isso vamos utilizar as seguintes frases :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcd5ddc-e937-49ce-a63b-7de8791e2087",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    \"John likes\",\n",
    "    \"likes to\",\n",
    "    \"to watch\",\n",
    "    \"watch movies\",\n",
    "    \"Mary likes\",\n",
    "    \"likes movies\",\n",
    "    \"movies too\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b3ac96-ba72-4619-9866-606f8050ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "frs = vectorizer.fit_transform(frases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8b874-810e-45ed-84f4-62ca99ddbac8",
   "metadata": {},
   "source": [
    "### A configuração padrão tokeniza a string extraindo palavras de pelo menos 2 letras. A função específica que faz esta etapa pode ser solicitada explicitamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927f05cd-1252-4dd9-8491-ec8c984fab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze = vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e764f4d-d7da-41fb-bec9-d4866335886f",
   "metadata": {},
   "source": [
    "### verificando se há compatibilidade com as palavras nas frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f291290-8220-42dc-8508-5d60df41da8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze(\"Este documento é para a análise também.\") == (['este', 'documento', 'para', 'análise', 'também'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a869a-ba7f-4874-be86-b947151e4d80",
   "metadata": {},
   "source": [
    "### Cada termo encontrado pelo analisador durante o ajuste recebe um índice inteiro único correspondente a uma coluna na matriz resultante. Essa interpretação das colunas pode ser recuperada da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72bfa43a-065b-41a5-bdb0-7d7f5d65629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['john', 'likes', 'mary', 'movies', 'to', 'too', 'watch'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cab45f4-32aa-462a-97ad-a685f02a7d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frs.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585949d4-32ea-45cf-9707-507fd04b9ea2",
   "metadata": {},
   "source": [
    "### O mapeamento inverso do nome do recurso para o índice da coluna é armazenado no atributo vocabulário_ do vetorizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab45169f-a0b9-4f6c-9d12-0de27dff4837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('mary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7f483-c8d9-48c7-b7d8-2aeddadfd562",
   "metadata": {},
   "source": [
    "### Portanto, palavras que não foram vistas no corpus de treinamento serão completamente ignoradas em futuras chamadas ao método transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae8e07be-0c1b-42c8-884c-72372029d929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['Something completely new.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7d7db-0be4-46f3-99b3-592c7abfee4a",
   "metadata": {},
   "source": [
    "### Observe que no corpus anterior, o primeiro e o último documentos têm exatamente as mesmas palavras, portanto, são codificados em vetores iguais. Em particular, perdemos a informação de que o último documento é uma forma interrogativa. Para preservar algumas das informações de pedidos locais, podemos extrair 2-grams de palavras além dos 1-grams (palavras individuais):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71f84af-72d4-4d43-b550-81eda80831a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),\n",
    "token_pattern=r'\\b\\w+\\b', min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "391a71ca-2d63-41c8-88a9-1ea5bf1e4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze = bigram_vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa43c2f-6043-40f6-8f5d-341d0a7ba4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze('Bi-gramas são legais!') == (\n",
    "     ['bi', 'gramas', 'são', 'legais', 'bi gramas', 'gramas são', 'são legais'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e790acb-724d-4efa-b096-8100ade4bb11",
   "metadata": {},
   "source": [
    "### O vocabulário extraído por este vetorizador é, portanto, muito maior e agora pode resolver ambiguidades codificadas em padrões de posicionamento local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d75f04e6-3dbe-46cf-bf47-5c6e0c1e80a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frs_1 = bigram_vectorizer.fit_transform(frases).toarray()\n",
    "frs_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a2d20-9e33-4eda-ac41-776a62f83bf2",
   "metadata": {},
   "source": [
    "### Em particular, a forma interrogativa “Este” está presente apenas no último documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e755f64e-f587-4947-81af-0f5138b0d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = bigram_vectorizer.vocabulary_.get('este')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "179399bd-8e34-4ebf-9031-13f9b06db465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]],\n",
       "\n",
       "       [[0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frs_1[:, feature_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adecfe-c193-4e9e-8b1e-1e1e7d673bfa",
   "metadata": {},
   "source": [
    "### Em um corpus de texto grande, algumas palavras estarão muito presentes (por exemplo, “the”, “a”, “is” em inglês), portanto, carregam muito pouca informação significativa sobre o conteúdo real do documento. Se fôssemos alimentar os dados de contagem direta diretamente para um classificador, esses termos muito frequentes sombreariam as frequências de termos mais raros, porém mais interessantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43760f72-0a87-4c1b-bc3e-92c4fc7924e3",
   "metadata": {},
   "source": [
    "### Para reponderar os recursos de contagem em valores de ponto flutuante adequados para uso por um classificador, é muito comum usar a transformada tf–idf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303417c3-5a38-4071-a1d2-69afb76f3c62",
   "metadata": {},
   "source": [
    "### Tf significa termo-frequência enquanto tf–idf significa o \"produto\" (termo-frequência vezes inversa do documento-frequência) \n",
    "### tf-idf(t,d) = tf(t,d) * idf(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd009a3-ec38-423f-9160-99772e670d4c",
   "metadata": {},
   "source": [
    "### Essa normalização é implementada pela classe TfidfTransformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f4937a9-4015-4c6d-8345-7edd710d7185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfTransformer(smooth_idf=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer(smooth_idf=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfTransformer(smooth_idf=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f04a36-98c9-4748-9bb9-082d021d95df",
   "metadata": {},
   "source": [
    "## Vamos dar um exemplo com as seguintes contagens. O primeiro termo está presente 100% do tempo, portanto, não é muito interessante. Os outros dois recursos apenas em menos de 50% do tempo, portanto, provavelmente mais representativos do conteúdo dos documentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45a82d64-be9d-4b5a-a0fa-06ab0e2f5a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [[3, 0, 1],\n",
    "           [2, 0, 0],\n",
    "           [3, 0, 0],\n",
    "           [4, 0, 0],\n",
    "           [3, 2, 0],\n",
    "           [3, 0, 2]]\n",
    "\n",
    "tfidf = transformer.fit_transform(counts)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8d0f2-100e-497c-8042-b018a9af7f41",
   "metadata": {},
   "source": [
    "### Cada linha é normalizada para ter a norma euclidiana unitária:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434ca80-5199-477d-b1bc-11c887fe51cb",
   "metadata": {},
   "source": [
    "### Além disso, o parâmetro padrão smooth_idf=True adiciona “1” ao numerador e denominador como se um documento extra fosse visto contendo todos os termos da coleção exatamente uma vez, o que evita divisões zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33b7b30c-6143-47f6-8ebf-b67b96becf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85151335, 0.        , 0.52433293],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.55422893, 0.83236428, 0.        ],\n",
       "       [0.63035731, 0.        , 0.77630514]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "transformer.fit_transform(counts).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f007b15-eea2-4f2d-b270-2723eb4a8fb4",
   "metadata": {},
   "source": [
    "### Os pesos de cada recurso calculados pela chamada do método fit são armazenados em um atributo de modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83bd4e2e-bb0c-4385-b6e7-e609334bb057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 2.25276297, 1.84729786])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f0961-5da6-4cf8-8ba8-cabea89918d7",
   "metadata": {},
   "source": [
    "### Como tf–idf é muito usado para recursos de texto, existe também outra classe chamada TfidfVectorizer que combina todas as opções de CountVectorizer e TfidfTransformer em um único modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8235de1c-38e0-4c17-8165-ea6f8e96f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(frases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4d0db-8346-4992-b86d-07f1af4627be",
   "metadata": {},
   "source": [
    "### Embora a normalização tf–idf seja frequentemente muito útil, pode haver casos em que os marcadores de ocorrência binários possam oferecer melhores recursos. Isso pode ser feito usando o parâmetro binário de CountVectorizer. Em particular, alguns estimadores como Bernoulli Naive Bayes modelam explicitamente variáveis ​​aleatórias booleanas discretas. Além disso, é provável que textos muito curtos tenham valores tf–idf ruidosos, enquanto as informações de ocorrência binária são mais estáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2ab2c-4554-4b7d-a99f-20dc565ff44d",
   "metadata": {},
   "source": [
    "### Como de costume, a melhor maneira de ajustar os parâmetros de extração de recursos é usar uma pesquisa de grade com validação cruzada, por exemplo, canalizando o extrator de recursos com um classificador:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf522236-d911-4e85-83bd-dcf4ea9a72b7",
   "metadata": {},
   "source": [
    "### Veja também amostra de Pipeline para extração e avaliação de recursos de texto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d91ef-ed54-4cfa-9e8c-1a1e09c36759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
